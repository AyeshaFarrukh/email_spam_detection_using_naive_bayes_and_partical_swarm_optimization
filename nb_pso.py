# -*- coding: utf-8 -*-
"""NB-PSO.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dGXvP-STo4iafkN78rmZuVtJJaYn88Zq
"""

# Importing necessary libraries
import pandas as pd
import numpy as np
import pyswarms as ps
import io
import re
import string

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report, accuracy_score
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import FunctionTransformer
from google.colab import files

# Load the dataset
uploaded = files.upload()
spam_df = pd.read_csv(io.BytesIO(uploaded['emails.csv']))

spam_df

spam_df.head(10)

spam_df.tail(10)

spam_df.describe()

spam_df.info()

# Visualize the Data
ham=spam_df[spam_df['label']==0]
spam=spam_df[spam_df['label']==1]

ham

spam

print('Spam Percentage =',(len(spam)/len(spam_df))*100,'%')

print('Ham Percentage =',(len(ham)/len(spam_df))*100,'%')

# functions

# Preprocessing
def preprocess_text(text):
    # Check if the text is not NaN (not a number), if so, convert it to empty string
    if pd.isnull(text):
        text = ''

    # Convert text to lowercase
    text = text.lower()

    # Remove punctuation
    text = text.translate(str.maketrans('', '', string.punctuation))

    # Return the cleaned text
    return text


  # Define objective function for PSO
def f(x, alpha=0.5):
    n_particles = x.shape[0]
    j = [None] * n_particles
    for i in range(n_particles):
        # Set the hyperparameter alpha for the Naive Bayes classifier

        alpha_value = x[i][0] if isinstance(x[i], (list, np.ndarray)) else x[i]

        classifier = MultinomialNB(alpha=alpha_value)
        classifier.fit(X_train, y_train)
        # Use a validation set or cross-validation to avoid overfitting the test set
        j[i] = cross_val_score(classifier, X_train, y_train, cv=5).mean()  # Using cross-validation
    return np.array(j)


# preprocessing
spam_df['message'] = spam_df['message'].apply(preprocess_text)

# Vectorize the text
vectorizer = CountVectorizer(preprocessor=preprocess_text)
X = vectorizer.fit_transform(spam_df['message'])

# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(X, spam_df['label'], test_size=0.3, random_state=42)

# Define the initial Naive Bayes model
nb_model = MultinomialNB()

# Train the model
nb_model.fit(X_train, y_train)

# Predict and evaluate the initial model
y_pred = nb_model.predict(X_test)
print(classification_report(y_test, y_pred))
print("Initial accuracy:", accuracy_score(y_test, y_pred))


# Set-up hyperparameters for PSO
options = {'c1': 1.49618, 'c2': 1.49618, 'w':0.7298, 'k': 20, 'p':2}

# Define bounds for alpha - ensure it's non-negative
# The lower bound is set to a small positive value to avoid alpha being exactly 0
# Adjusting the upper bound as per my requirement
bounds = ([0.01], [20.0])

# Create a PSO instance
optimizer = ps.single.GlobalBestPSO(n_particles=8, dimensions=1, options=options, bounds=bounds)

# Perform optimization
cost, pos = optimizer.optimize(f, iters=50)

# Apply the optimized hyperparameters
nb_optimized = MultinomialNB(alpha=pos[0])
nb_optimized.fit(X_train, y_train)

# Predict and evaluate the optimized model
y_pred_optimized = nb_optimized.predict(X_test)
print(classification_report(y_test, y_pred_optimized))
print("Optimized accuracy:", accuracy_score(y_test, y_pred_optimized))